{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import skimage, skimage.transform, skimage.data\n",
    "from skimage.feature import register_translation\n",
    "from typing import NamedTuple, Optional, List, Tuple\n",
    "import tensorflow as tf\n",
    "import attr\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pandas import DataFrame\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSampleObj(npix: int = 256, \n",
    "                 mod_range: float = 1, \n",
    "                 phase_range: float = np.pi)-> np.ndarray:\n",
    "    r\"\"\"Creates a sample complex-valued object using stock data from the skimage library.\n",
    "    \n",
    "    Uses the stock camera image for the phase and the stock immunohistochemistry image (channel 0) for the modulus [1]_.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    npix : int\n",
    "        Number of pixels in each axis of the object\n",
    "    mod_range : float \n",
    "        Maximum value of the modulus for the object pixels.\n",
    "    phase_range : float\n",
    "        Maximum value of the phase for the object pixels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : complex ndarray\n",
    "        A 2d array of shape npix x npix and dtype complex64.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] https://scikit-image.org/docs/dev/api/skimage.data.html\n",
    "    \"\"\"\n",
    "    \n",
    "    phase_img = skimage.img_as_float(skimage.data.camera())[::-1,::-1]\n",
    "    mod_img = skimage.img_as_float(skimage.data.immunohistochemistry()[:,:,0])[::-1,::-1]\n",
    "    mod = skimage.transform.resize(mod_img, [npix, npix], \n",
    "                                   mode='wrap', preserve_range=True) \n",
    "    phase = skimage.transform.resize(phase_img, [npix, npix],\n",
    "                                     mode='wrap', preserve_range=True)\n",
    "    \n",
    "    # Setting the ranges\n",
    "    phase = (phase - np.min(phase)) / (np.max(phase) - np.min(phase)) * phase_range\n",
    "    mod = (mod - np.min(mod)) / (np.max(mod) - np.min(mod)) * mod_range\n",
    "    \n",
    "    # Centering the phase at 0.\n",
    "    phase = np.angle(np.exp(1j * (phase - scipy.stats.circmean(phase))))\n",
    "    \n",
    "    obj = mod * np.exp(1j * phase)\n",
    "    return obj.astype('complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaussian2D(npix: int, \n",
    "                  stdev: Optional[float] = None,\n",
    "                  fwhm: Optional[float] = None) -> np.ndarray:\n",
    "    r\"\"\"Generates a circularly symmetric 2d gaussian pattern. \n",
    "    \n",
    "    Ignoring the scaling constants, a circularly symmetric 2d gaussian can be calculated as:\n",
    "    \n",
    "    .. math:: g = \\exp\\left(-\\frac{(x - c_x)^2 + (y - c_y)^2}{2 * stdev^2}\\right)\n",
    "    \n",
    "    where :math:`(x,y)` are the coordinate indices, :math:`(c_x, c_y)` are the coordinates for the center of the gaussian, and stdev is the standard deviation. In this function, we assume that :math:`c_x = c_y = npix // 2` (i.e. the center of the gaussian is the center of the 2d array).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    npix : int\n",
    "        Number of pixels in each axis of the probe\n",
    "    stdev : :obj:`float`, optional\n",
    "        Standard deviation of the gaussian. The function requires either the standard deviation or the fwhm. \n",
    "    fwhm : :obj:`float`, optional\n",
    "        Full width at half maximum (FWHM) of the peak. The function requires either the standard deviation or the fwhm. If we supply the fwhm, the standard deviation is calculated as :math:`stdev = fwhm / 2.35682`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out: float ndarray\n",
    "        A 2d array of shape npix X npix and dtype float32.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if ((stdev is None) and (fwhm is None)) or ((stdev is not None) and (fwhm is not None)):\n",
    "        raise KeyError(\"Should input only one of either stdev or fwhm.\")\n",
    "    if fwhm:\n",
    "        stdev = fwhm / 2.35682\n",
    "    \n",
    "    center = npix // 2\n",
    "    xvals = np.arange(npix)\n",
    "    XX, YY = np.meshgrid(xvals, xvals)\n",
    "    r_squared = (XX - center)**2 + (YY - center)**2\n",
    "    \n",
    "    # Ignoring the normalization constants\n",
    "    gaussian = np.exp(-r_squared/ (2 * stdev**2)) \n",
    "    return gaussian.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFPropKernel(beam_shape: tuple, \n",
    "                    pixel_pitch: float, \n",
    "                    wavelength: float, \n",
    "                    prop_dist: float,\n",
    "                    fftshift: bool = True) -> np.ndarray:\n",
    "    r\"\"\"Generates a kernel for wavefield propagation using the Transfer function method. \n",
    "    \n",
    "    This implementation is adapted slightly the reference algorithm in [2]_. The expression used is:\n",
    "    \n",
    "    .. math:: H(f_x, f_y) = \\exp\\left(-j \\pi \\lambda z (f_x^2 + f_y^2)\\right)\n",
    "    \n",
    "    where :math:`(f_x, f_y)` are the coordinates in reciprocal space (which are calculated using the pixel pitch), :math:`z` is the propagation distance, and :math:`\\lambda` is the wavelength.\n",
    "    \n",
    "    Note that this is equivalent to the angular spectrum propagator used in Equation 14 in [3]_ , which is itself sourced from Equation 4 in [4]_. In these equations, we see the coordinates :math:`(q_x, q_y)` and :math:`(u, v)`---these are the *angular* coordinates, which correspond to the *frequency* coordinates used herein, i.e. :math:`(q_x = u = 2 * \\pi * f_x)`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beam_shape : tuple(int, int)\n",
    "        A tuple for the shape of the array containing the propagation kernel.\n",
    "    pixel_pitch : float\n",
    "        Pixel pitch at plane containing the initial wavefront (in SI units).\n",
    "    wavelength : float\n",
    "        Wavelength of the propagated wave (in SI units).\n",
    "    prop_dist : float\n",
    "        Propagation distance (in SI units).\n",
    "    fftshift : bool\n",
    "        Whether to return the kernel after performing an fftshift. Since we most often use the output kernel (H) inside the structure IFFT(FFT(psi) * H) where psi is the wavefront that we need to propagate, it is convenient to deal with the shifted kernel directly. \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    out : complex ndarray\n",
    "        A 2d array of shape beam_shape and dtype complex64.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [2] Chapter 5.1 of the book \"Computational Fourier Optics: A MATLAB Tutorial\" by David Voelz (2011).\n",
    "    .. [3] Saugat Kandel, S. Maddali, Marc Allain, Stephan O. Hruszkewycz, Chris Jacobsen, and Youssef S. G. Nashed, \"Using automatic differentiation as a general framework for ptychographic reconstruction,\" Opt. Express 27, 18653-18672 (2019)\n",
    "    .. [4] Richard M. Clare, Marco Stockmar, Martin Dierolf, Irene Zanette, and Franz Pfeiffer, \"Characterization of near-field ptychography,\" Opt. Express 23, 19728-19742 (2015)\n",
    "    \"\"\"\n",
    "    \n",
    "    M, N = beam_shape\n",
    "    \n",
    "    fx = np.fft.fftfreq(M, d=pixel_pitch)\n",
    "    fy = np.fft.fftfreq(N, d=pixel_pitch)\n",
    "    \n",
    "    FX, FY = np.meshgrid(fx, fy)\n",
    "    FX = np.fft.fftshift(FX)\n",
    "    FY = np.fft.fftshift(FY)\n",
    "    \n",
    "    H = np.exp(-1j * np.pi * wavelength * prop_dist * (FX**2 + FY**2))\n",
    "    if fftshift: \n",
    "        H = np.fft.fftshift(H)\n",
    "    return H.astype('complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeckle(npix: int, \n",
    "               window_size: int) -> np.ndarray:\n",
    "    \"\"\"Generates a speckle pattern. \n",
    "    \n",
    "    To generate a speckle pattern, this function uses a window_size x window_size array of complex numbers with unit amplitude and uniformly random phase. This array is padded with zeros to get an npix x npix array, an FFT of which gives us a speckle pattern. The speckle pattern thus generated is discontinuous; there is a phase step of pi between adjacent pixels in both the x and y directions. We remove these discontinuities to get the final, continuous, speckle pattern.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    npix : int\n",
    "        Number of pixels along each side of the 2d array containing the speckle pattern.\n",
    "    window_size : int \n",
    "        The size of the rectangular window used to generate the speckle pattern. Larger window sizes give smaller speckle sizes and vice versa. (*Note*: I tried a circular window as well, but the results did not change \n",
    "    noticeably.)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    out : complex ndarray\n",
    "        A 2d array of size npix x npix and dtype complex64.\n",
    "    \"\"\"\n",
    "    \n",
    "    if window_size > npix: \n",
    "        raise ValueError(\"Window size should be smaller than the size of output array.\")\n",
    "    \n",
    "    # generating the random array\n",
    "    ran = np.exp(1j * np.random.rand(npix,npix) * 2 * np.pi)\n",
    "    \n",
    "    window = np.zeros((npix, npix))\n",
    "    indx1 = npix // 2 - window_size // 2\n",
    "    indx2 = npix // 2 + window_size // 2\n",
    "    window[indx1: indx2, indx1: indx2] = 1\n",
    "    \n",
    "    # Circular window - doesn't change the results.\n",
    "    #xx, yy = np.meshgrid(np.arange(npix), np.arange(npix))\n",
    "    #mask = ((xx - npix // 2)**2 + (yy - npix // 2)**2 < (window_size // 2)**2)\n",
    "    #window[mask] = 1\n",
    "    \n",
    "    t = window * ran\n",
    "    \n",
    "    ft = np.fft.fftshift(np.fft.fft2(t, norm='ortho'))\n",
    "    absvals = np.abs(ft)\n",
    "    angvals = np.angle(ft)\n",
    "    \n",
    "    # Removing the discontinuities in the phases \n",
    "    angvals[::2] = (angvals[::2] + np.pi) % (2 * np.pi)\n",
    "    angvals[:,::2] = (angvals[:, ::2] + np.pi) % (2 * np.pi)\n",
    "    return (absvals * np.exp(1j * angvals)).astype('complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ObjParams:\n",
    "    \"\"\"Convenience class to store the object parameters.\n",
    "    \n",
    "    Note\n",
    "    -----\n",
    "    Adding an assumed-known border (filled with ones) to the object helps avoid the affine phase ambiguity.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    obj_npix : int\n",
    "        Number of pixels in each side of the (square) object to be generated.\n",
    "    mod_range : float\n",
    "        Maximum value of the modulus for the object pixels.\n",
    "    phase_range : float\n",
    "        Maximum value of the phase for the object pixels. \n",
    "    border_npix : int\n",
    "        Number of pixels to add along the border in the left, right, top, and bottom margins of the object. If :obj:`border_npix = 10`, then the simulation adds 10 pixels to the left of the object, and 10 pixels to the right of the object, i.e. a total of 20 pixels along the x-direction (and similarly with y). \n",
    "    border_const : float\n",
    "        Constant value to fill the border with.\n",
    "    \"\"\"\n",
    "    obj_npix: int\n",
    "    mod_range: float\n",
    "    phase_range: float\n",
    "    border_npix: int\n",
    "    border_const: float\n",
    "    \n",
    "    @property\n",
    "    def obj_w_border_npix(self) -> int:\n",
    "        \"\"\"Total number of pixels (including object and border) in each side of the object.\"\"\"\n",
    "        return self.obj_npix + 2 * self.border_npix\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ProbeParams:\n",
    "    \"\"\"Convenience class to store the probe parameters.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    wavelength : float\n",
    "        Wavelength of the probe beam.\n",
    "    npix : int\n",
    "        Number of pixels in each side of the square probe to be generated.\n",
    "    photons_flux : float \n",
    "        Average number of photons per pixel in the probe beam. \n",
    "    \"\"\"\n",
    "    wavelength: float\n",
    "    npix: int\n",
    "    photons_flux: float\n",
    "    \n",
    "    @property\n",
    "    def n_photons(self) -> float:\n",
    "        \"\"\"Total number of photons in the beam.\"\"\"\n",
    "        return self.photons_flux * self.npix**2\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DetectorParams:\n",
    "    \"\"\"Convenience class to store the detector parameters.\n",
    "    \n",
    "    Attributes\n",
    "    -----------\n",
    "    obj_dist : float\n",
    "        Object-detector distance (in m).\n",
    "    pixel_pitch : float\n",
    "        Width of each individual pixel (in m). \n",
    "    \"\"\"\n",
    "    obj_dist: float\n",
    "    pixel_pitch: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ScanParams:\n",
    "    \"\"\"Convenience class to store the ptychographic scan parameters.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    scan_step_npix : int\n",
    "        Number of pixels per step in the raster grid.\n",
    "    poisson_noise : bool\n",
    "        Whether to simulate Poisson noise in the diffraction data.\n",
    "    \"\"\"\n",
    "    scan_step_npix: int\n",
    "    poisson_noise: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class NFSimObjParams(ObjParams): \n",
    "    \"\"\"Customizing ObjParams with some default parameters for nearfield simulations.\n",
    "    \n",
    "    Only function is to use the default parameters. Does not extend ObjParams. \n",
    "    \n",
    "    See ObjParams for documentation on the individual parameters used.\n",
    "    \"\"\"\n",
    "    obj_npix : int = 192\n",
    "    mod_range: float = 1.0\n",
    "    phase_range: float = np.pi\n",
    "    border_npix: int = 32\n",
    "    border_const: float = 1.0\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class NFSimDetectorParams(DetectorParams):\n",
    "    \"\"\"Customizing DetectorParams with some default parameters for nearfield simulations.\n",
    "    \n",
    "    Only function is to use the default parameters. Does not extend ObjParams. \n",
    "    \n",
    "    See ObjParams for documentation on the individual parameters used..\"\"\"\n",
    "    obj_dist: float = 0.0468\n",
    "    pixel_pitch: float = 3e-7\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class NFSimProbeParams(ProbeParams):\n",
    "    \"\"\"Customizes ProbeParams with default parameter values and also adds parameters specific to the nearfield simulation.\n",
    "    \n",
    "    For detail on the other attributes and parameters, refer to the documentation for the ProbeParams class.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    gaussian_intensity_stdev_pix : float\n",
    "        Standard deviation of the gaussian probe to be used. See the function getGaussian2D for more detailed information on this parameter.\n",
    "    speckle_window_pix : int\n",
    "        The size of the rectangular window used to generate the speckle pattern. See the function getSpeckle for more detail on this parameter. \n",
    "    \"\"\"\n",
    "    wavelength: float = 0.142e-9\n",
    "    npix: int = 512\n",
    "    photons_flux: float = 1e4\n",
    "    gaussian_intensity_stdev_npix: float = 150.0\n",
    "    speckle_window_npix: int = 40\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class NFSimScanParams(ScanParams):\n",
    "    r\"\"\"\"Customizes ScanParams with default parameter values and also adds parameters specific to the nearfield simulation.\n",
    "    \n",
    "    For detail on the other parameters, refer to the documentation for the ScanParams class.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    scan_area_buffer_npix : int\n",
    "        This is a bit of hack to ensure that the scan area is around the center of the full-field probe. For e.g., if scan_area_buffer_npix = 20, we start the ptychographic scan from the coordinate (20, 20) of the probe instead of from (0,0). The regions between x=[0,20] and y=[0,20] are never sampled.\n",
    "        Basically, this is like imposing a margin of 20 pixels in the left and bottom of the probe.\n",
    "        \n",
    "        \"\"\"\n",
    "    scan_step_npix: int = 44\n",
    "    poisson_noise: bool = True\n",
    "    scan_area_buffer_npix: int = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFPtychoSimulation(object):\n",
    "    r\"\"\"Simulate a near-field ptychography simulation using a full-field probe and object translations.\n",
    "        \n",
    "    I don't know if this is the typical scenario for a near-field ptychography experiment. For this work, I am trying to use a similar setup to that used by Clare et al in [6]_.\n",
    "\n",
    "    See NFSimObjParams, NFSimProbeParams, NFSimDetectorParams, and NFSimScanParams classes for details on the options available to customize the simulation.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    obj_params : NFSimObjParams\n",
    "        Parameters for the simulated object.\n",
    "    probe_params : NFSimProbeParams\n",
    "        Parameters for simulated probe.\n",
    "    det_params : NFSimDetectorParams\n",
    "        Parameters for simulated detector.\n",
    "    scan_params : NFSimScanParams\n",
    "        Parameters for the scan grid and noise setup.\n",
    "    obj_true: complex ndarray\n",
    "        Holds the generated complex valued object.\n",
    "    obj_w_border: complex ndarray\n",
    "        Holds the generated complex valued object along with the border specified through obj_params.\n",
    "    probe_true: complex ndarray\n",
    "        Holds the generated complex valued probe.\n",
    "    prop_kernel: complex ndarray\n",
    "        Holds the (fft-shifted) Fresnel propagation kernel for the simulation parameters. \n",
    "    positions : int ndarray\n",
    "        Holds the scan positions (object translations) used for the ptychographic scan.\n",
    "    diffraction_mods : float ndarray\n",
    "        Holds the modulus of the exit wave at the detector plane for the scan positions. This is just the square root of the intensity pattern at the object plane.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    obj_args : dict\n",
    "        Dictionary that contains pairs of arguments and values to use to create a custom NFSimObjParams class, and thus change the parameters of the simulated object. \n",
    "    probe_args : dict\n",
    "        Dictionary that contains pairs of arguments and values to use to create a custom NFSimProbeParams class, and thus change the parameters of the simulated probe. \n",
    "    detector_args : dict\n",
    "        Dictionary that contains pairs of arguments and values to use to create a custom NFSimDetectorParams class, and thus change the parameters of the detector used. \n",
    "    scan_args : dict\n",
    "        Dictionary that contains pairs of arguments and values to use to create a custom NFSimScanParams class, and thus change the parameters of the ptychographic scan. \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Input parameter examples: \n",
    "    \n",
    "    * If we want to use an object 64 pixels wide, and with of border of 5 pixels on each side, we use: \n",
    "        ``nfsim = NFPtychoSimulation(obj_args={obj_npix:64, border_npix:5})``\n",
    "    * If we want to use an object 1024 pixels wide, and with a wavelength of 1 nm, we use:\n",
    "        ``nfsim = NFPtychoSimulation(probe_args={probe_npix:1024, wavelength:1e-9})``\n",
    "    * If we want to use a detector with pixel pitch 100nm, we use:\n",
    "        ``nfsim = NFPtychoSimulation(detector_args={pixel_pitch:100e-9})``\n",
    "    * If we want to use a step size of 60 pixels, and generate diffraction patterns without Poisson noise included, we use:\n",
    "        ``nfsim = NFPtychoSimulation(scan_args={scan_step_npix:60, poisson_noise=False})``\n",
    "\n",
    "    References\n",
    "    -----------\n",
    "    .. [6] Richard M. Clare, Marco Stockmar, Martin Dierolf, Irene Zanette, and Franz Pfeiffer, \"Characterization of near-field ptychography,\" Opt. Express 23, 19728-19742 (2015).\n",
    "        \n",
    "        \"\"\"\n",
    "    def __init__(self,\n",
    "                 obj_args: dict = {},\n",
    "                 probe_args: dict = {},\n",
    "                 detector_args: dict = {},\n",
    "                 scan_args: dict = {}) -> None:\n",
    "  \n",
    "        self.obj_params = NFSimObjParams(**obj_args)\n",
    "        self.probe_params = NFSimProbeParams(**probe_args)\n",
    "        self.det_params = NFSimDetectorParams(**detector_args)\n",
    "        self.scan_params = NFSimScanParams(**scan_args)\n",
    "        \n",
    "        self.checkValidity()\n",
    "        \n",
    "        # Generating the simulated object\n",
    "        self.obj_true = getSampleObj(npix=self.obj_params.obj_npix,\n",
    "                                      mod_range=self.obj_params.mod_range,\n",
    "                                      phase_range=self.obj_params.phase_range)\n",
    "        pad = self.obj_params.border_npix\n",
    "        self.obj_w_border = np.pad(self.obj_true, [[pad,pad],[pad,pad]], \n",
    "                                      mode='constant',\n",
    "                                      constant_values=self.obj_params.border_const)\n",
    "        \n",
    "        # Generating the simulated probe\n",
    "        gaussian_intensity = getGaussian2D(self.probe_params.npix, \n",
    "                                           self.probe_params.gaussian_intensity_stdev_npix)\n",
    "        gaussian_ampl = gaussian_intensity**0.5\n",
    "        speckle = getSpeckle(self.probe_params.npix, \n",
    "                             self.probe_params.speckle_window_npix)\n",
    "        probe_data = gaussian_ampl * speckle\n",
    "        self.probe_true = probe_data * np.sqrt(self.probe_params.n_photons \n",
    "                                         / np.sum(np.abs(probe_data)**2))\n",
    "        \n",
    "        # Generating the fft-shifted propagation kernel \n",
    "        self.prop_kernel = getTFPropKernel(beam_shape=self.probe_true.shape,\n",
    "                                           pixel_pitch=self.det_params.pixel_pitch,\n",
    "                                           wavelength=self.probe_params.wavelength,\n",
    "                                           prop_dist=self.det_params.obj_dist)\n",
    "        \n",
    "        self.genPtychographyPositions()\n",
    "        self.genDiffractionMods()\n",
    "        self.ndiffs = self.diffraction_mods.shape[0]    \n",
    "        \n",
    "    def checkValidity(self) -> None:\n",
    "        \"\"\"Checking if the parameters supplied are valid. \n",
    "        \n",
    "        For now, we only check to ensure that the step size supplied is larger than the \n",
    "        width of the Fresnel zone for the simulation parameters. This ensures that the \n",
    "        generated diffraction patterns have enough diversity.\n",
    "        \n",
    "        Need to add more checks here.\n",
    "        \"\"\"\n",
    "        \n",
    "        fresnel_zone_dist = np.sqrt(self.probe_params.wavelength * self.det_params.obj_dist)\n",
    "        fresnel_zone_npix = fresnel_zone_dist / self.det_params.pixel_pitch\n",
    "        \n",
    "        error_str = (f\"Step size ({self.scan_params.scan_step_npix} is too small. \"\n",
    "                     + f\"Ensure that the step size is at least larger than the Fresnel zone width \"\n",
    "                     + f\"({fresnel_zone_npix}) to ensure diversity in the diffraction patterns.\")\n",
    "        assert self.scan_params.scan_step_npix > fresnel_zone_npix, error_str  \n",
    "    \n",
    "    def genPtychographyPositions(self) -> None:\n",
    "        \"\"\"Generate the scan positions for the ptychographic scan.\"\"\"\n",
    "        \n",
    "        p1 = self.scan_params.scan_area_buffer_npix\n",
    "        p2 = self.probe_params.npix - p1 - self.obj_params.obj_w_border_npix\n",
    "        positions_x = np.arange(p1, p2, self.scan_params.scan_step_npix)\n",
    "        positions = []\n",
    "        \n",
    "        for r in positions_x:\n",
    "            for c in positions_x:\n",
    "                positions.append([r,c])\n",
    "        self.positions = np.array(positions)\n",
    "    \n",
    "    def genDiffractionMods(self) -> None:\n",
    "        \"\"\"Generate the near-field diffraction patterns for the ptychography scan using the transfer function method.\"\"\"\n",
    "        diffraction_intensities = []\n",
    "        \n",
    "        npix_pad = self.probe_params.npix - self.obj_params.obj_w_border_npix\n",
    "        obj_padded_to_probe = np.pad(self.obj_w_border, \n",
    "                                     [[0, npix_pad], [0, npix_pad]],\n",
    "                                     mode='constant',\n",
    "                                     constant_values=1.0)\n",
    "        for indx, (r,c) in enumerate(self.positions):\n",
    "            exit_wave = self.probe_true * np.roll(obj_padded_to_probe, [r,c], axis=(0,1)) \n",
    "            nearfield_wave = np.fft.ifftshift(np.fft.ifft2(self.prop_kernel * np.fft.fft2(exit_wave)))\n",
    "            diffraction_intensities.append(np.abs(nearfield_wave)**2)\n",
    "            \n",
    "        if self.scan_params.poisson_noise: \n",
    "            diffraction_intensities = np.random.poisson(diffraction_intensities)\n",
    "        self.diffraction_mods = np.sqrt(diffraction_intensities)\n",
    "        \n",
    "    def getScatterIndices(self) -> None:\n",
    "        \"\"\"Not in use right now\"\"\"\n",
    "        scatter_indices_all = []\n",
    "        for py, px in self.positions:\n",
    "            R, C = np.ogrid[py:self.obj_params.obj_w_border_npix + py, \n",
    "                            px:self.obj_params.obj_w_border_npix + px]\n",
    "            scatter_single = ((R % self.probe_params.npix) * self.probe_params.npix + \n",
    "                              (C % self.probe_params.npix))\n",
    "            scatter_indices_all.append(scatter_single)\n",
    "        scatter_indices =  np.array(scatter_indices_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tfNearFieldPtychoRecons(object):\n",
    "    \"\"\"Reconstruct the object and probe from a near-field ptychography simulation. \n",
    "\n",
    "    Assumes that the probe is full-field, the object is (much) smaller than the probe, and the object is translated within the probe field to generate the diffraction patterns. \n",
    "\n",
    "    Assumes square object and probe.\n",
    "\n",
    "    Uses the gaussian noise model for the loss function. This is easy to change if neeeded.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    test\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 positions: np.ndarray,\n",
    "                 diffraction_mods: np.ndarray,\n",
    "                 wavelength: float,\n",
    "                 obj_detector_dist: float,\n",
    "                 detector_pixel_pitch: float,\n",
    "                 obj_npix: int = 0,\n",
    "                 obj_border_npix: int = 0,\n",
    "                 obj_border_const: float = 0.0,\n",
    "                 obj_mod_range: float = 1.0,\n",
    "                 probe_npix: int = 0,\n",
    "                 obj_guess: Optional[np.ndarray] = None,\n",
    "                 probe_guess: Optional[np.ndarray] = None,\n",
    "                 probe_recons: bool = False,\n",
    "                 batch_size: int = 0,\n",
    "                 n_validation_diffs: int = 0,\n",
    "                 obj_true: Optional[np.ndarray] = None,\n",
    "                 probe_true: Optional[np.ndarray] = None) -> None:\n",
    "                 \n",
    "\n",
    "        \n",
    "        self.positions = positions\n",
    "        self.diffraction_mods = diffraction_mods\n",
    "        self.diffraction_mods_shifted = np.fft.fftshift(self.diffraction_mods, axes=(-1,-2))\n",
    "        \n",
    "        obj_npix = obj_guess.shape[0] if obj_guess is not None else obj_npix\n",
    "        assert obj_npix > 0, \"Need to supply either obj_guess or obj_npix\"\n",
    "        self.obj_params = ObjParams(obj_npix=obj_npix, \n",
    "                                    mod_range=obj_mod_range,\n",
    "                                    border_npix=obj_border_npix,\n",
    "                                    border_const=obj_border_const)\n",
    "        \n",
    "        self.probe_recons = probe_recons\n",
    "        probe_npix = probe_guess.shape[0] if probe_guess is not None else probe_npix\n",
    "        assert probe_npix > 0, \"Need to supply either probe_guess or probe_npix\"\n",
    "        if not probe_recons:\n",
    "            assert (probe_guess is not None), \"Need to supply probe array if probe_recons is False.\"\n",
    "        \n",
    "        self.probe_params = ProbeParams(npix=probe_npix,\n",
    "                                        wavelength=wavelength)\n",
    "        \n",
    "        self.det_params = DetectorParams(obj_dist=obj_detector_dist,\n",
    "                                         pixel_pitch=detector_pixel_pitch)\n",
    "        \n",
    "        self.prop_kernel = getTFPropKernel(beam_shape=(probe_npix, probe_npix),\n",
    "                                           pixel_pitch=detector_pixel_pitch,\n",
    "                                           wavelength=wavelength,\n",
    "                                           prop_dist=obj_detector_dist)\n",
    "        \n",
    "        self.setObjProbeGuess(obj_guess, probe_guess)\n",
    "        self.setTrainingAndValidation(n_validation_diffs, batch_size)\n",
    "        \n",
    "        # Tensorflow setup\n",
    "        self.createGraphAndVars()\n",
    "        self.initDataSet()\n",
    "        \n",
    "        self.obj_true = obj_true\n",
    "        self.probe_true = probe_true\n",
    "        self.optimizers_defined = False\n",
    "        \n",
    "        self.data = DataFrame(columns=['loss','epoch','obj_error','probe_error','validation_loss','patience'],\n",
    "                              dtype='float32')\n",
    "        \n",
    "    \n",
    "    def setTrainingAndValidation(self, \n",
    "                                 n_validation_diffs,\n",
    "                                 batch_size):\n",
    "        self.ndiffs = self.diffraction_mods.shape[0]\n",
    "        \n",
    "        self.n_validation_diffs = n_validation_diffs\n",
    "        self.validation_indices = np.random.permutation(self.ndiffs)[:self.n_validation_diffs]\n",
    "        \n",
    "        self.train_ndiffs = self.ndiffs - self.n_validation_diffs\n",
    "        self.train_indices = np.array([i for i in range(self.ndiffs) if i not in self.validation_indices])\n",
    "        \n",
    "        self.batch_size = self.train_ndiffs if batch_size==0 else batch_size \n",
    "    \n",
    "    def setObjProbeGuess(self, obj_guess, probe_guess):\n",
    "        \n",
    "        if obj_guess is None:\n",
    "            n = self.obj_params.obj_npix\n",
    "            obj_guess = (np.random.random((n,n)) * np.exp(1j * np.random.random((n,n)) * np.pi))\n",
    "        self.obj_guess = obj_guess \n",
    "\n",
    "        if probe_guess is None:\n",
    "            mods_avg = np.mean(self.diffraction_mods_shifted, axis=0)\n",
    "            probe_guess = np.fft.ifftshift(np.fft.ifft2(np.fft.fft2(mods_avg) \n",
    "                                                        / self.prop_kernel))\n",
    "        self.probe_guess = probe_guess\n",
    "        \n",
    "        \n",
    "    def createGraphAndVars(self) -> None:\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.tf_obj_var = tf.Variable(np.array([np.real(self.obj_guess), \n",
    "                                                    np.imag(self.obj_guess)]),\n",
    "                                          dtype='float32')\n",
    "            self.tf_obj = tf.complex(self.tf_obj_var[0], self.tf_obj_var[1])\n",
    "            \n",
    "            \n",
    "            self.tf_probe_var = tf.Variable(np.array([np.real(self.probe_guess), \n",
    "                                                    np.imag(self.probe_guess)]),\n",
    "                                          dtype='float32')\n",
    "            self.tf_probe = tf.complex(self.tf_probe_var[0], self.tf_probe_var[1])\n",
    "\n",
    "            self.tf_train_mods = tf.constant(self.diffraction_mods_shifted[self.train_indices],\n",
    "                                                        dtype='float32')\n",
    "            self.tf_validation_mods = tf.constant(self.diffraction_mods_shifted[self.validation_indices],\n",
    "                                                             dtype='float32')\n",
    "\n",
    "            self.tf_prop_kernel = tf.constant(self.prop_kernel, dtype='complex64', name='propagation_kernel')\n",
    "            \n",
    "            pad = self.obj_params.border_npix\n",
    "            self.tf_obj_w_border = tf.pad(self.tf_obj, [[pad, pad], [pad, pad]], \n",
    "                                          constant_values=self.obj_params.border_const)\n",
    "            \n",
    "            self.tf_train_obj_views = self.getObjViewsStack(self.train_indices)\n",
    "            self.tf_validation_obj_views = self.getObjViewsStack(self.validation_indices)\n",
    "    \n",
    "    def initDataSet(self) -> None:\n",
    "        with self.graph.as_default():\n",
    "            dataset_indices = tf.data.Dataset.range(self.train_ndiffs)\n",
    "            dataset_indices = dataset_indices.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=self.train_ndiffs))\n",
    "            dataset_batch = dataset_indices.batch(self.batch_size, drop_remainder=True)\n",
    "            self.dataset_batch = dataset_batch.apply(tf.data.experimental.prefetch_to_device('/gpu:0', buffer_size=5))\n",
    "            \n",
    "            self.iterator = self.dataset_batch.make_one_shot_iterator()\n",
    "\n",
    "            batchi = self.iterator.get_next()\n",
    "            self.batch_indices = tf.Variable(tf.zeros(self.batch_size, dtype=tf.int64),\n",
    "                                             name='batch_indices', trainable=False)\n",
    "            self.batch_assign_op = self.batch_indices.assign(batchi)\n",
    "            \n",
    "            self.batch_train_mods = tf.gather(self.tf_train_mods, self.batch_indices)\n",
    "            self.batch_train_obj_views = tf.gather(self.tf_train_obj_views, self.batch_indices)\n",
    "    \n",
    "    def getObjViewsStack(self, indices):\n",
    "        obj_real_pads = []\n",
    "        obj_imag_pads = []\n",
    "        n1 = self.obj_params.obj_w_border_npix\n",
    "        n2 = self.probe_params.npix\n",
    "        for p in self.positions[indices]:\n",
    "    \n",
    "            padded_real = tf.pad(tf.real(self.tf_obj_w_border), [[p[0], n2 - (n1+p[0])],\n",
    "                                                                 [p[1], n2 - (n1+p[1])]],\n",
    "                                 constant_values=1)\n",
    "            padded_imag = tf.pad(tf.imag(self.tf_obj_w_border), [[p[0], n2 - (n1+p[0])],\n",
    "                                                                 [p[1], n2 - (n1+p[1])]],\n",
    "                                 constant_values=0)\n",
    "            obj_real_pads.append(padded_real)\n",
    "            obj_imag_pads.append(padded_imag)\n",
    "\n",
    "        obj_real_pads = tf.stack(obj_real_pads)\n",
    "        obj_imag_pads = tf.stack(obj_imag_pads)\n",
    "        \n",
    "        obj_views = tf.complex(obj_real_pads, obj_imag_pads)\n",
    "        return obj_views\n",
    "    \n",
    "    \n",
    "    def getBatchPredictedData(self, obj_views) -> tf.Tensor:\n",
    "        if obj_views.get_shape()[0] == 0:\n",
    "            return tf.zeros(shape=[], dtype='float32')\n",
    "        \n",
    "        exit_waves = obj_views * self.tf_probe\n",
    "        out_wavefronts = (tf.ifft2d(tf.fft2d(exit_waves) * self.tf_prop_kernel))\n",
    "        guess_mods = tf.abs(out_wavefronts)\n",
    "        return guess_mods\n",
    "        \n",
    "\n",
    "    def getBatchAmplitudeLoss(self, predicted_data, measured_data) -> tf.Tensor:\n",
    "        loss = 0.5 * tf.reduce_sum((predicted_data - measured_data)**2)\n",
    "        return loss\n",
    "\n",
    "    def setLossAndOptimizers(self, \n",
    "                             obj_learning_rate: float = 1e-2, \n",
    "                             probe_learning_rate: float = 1e-1) -> None:\n",
    "        with self.graph.as_default():\n",
    "            self.training_predictions = self.getBatchPredictedData(self.batch_train_obj_views)\n",
    "            self.training_loss = self.getBatchAmplitudeLoss(self.training_predictions,\n",
    "                                                            self.batch_train_mods)\n",
    "            \n",
    "            self.validation_predictions = self.getBatchPredictedData(self.tf_validation_obj_views)\n",
    "            self.validation_loss = self.getBatchAmplitudeLoss(self.validation_predictions, \n",
    "                                                              self.tf_validation_mods)\n",
    "            \n",
    "            self.obj_learning_rate = obj_learning_rate\n",
    "            self.probe_learning_rate = probe_learning_rate\n",
    "            \n",
    "            self.obj_optimizer = tf.train.AdamOptimizer(self.obj_learning_rate)\n",
    "            self.obj_minimize_op = self.obj_optimizer.minimize(self.training_loss,\n",
    "                                                               var_list=[self.tf_obj_var])\n",
    "            \n",
    "            if self.probe_recons:\n",
    "                self.probe_optimizer = tf.train.AdamOptimizer(self.probe_learning_rate)\n",
    "                self.probe_minimize_op = self.probe_optimizer.minimize(self.training_loss, \n",
    "                                                                       var_list=[self.tf_probe_var])\n",
    "        self.optimizers_defined = True\n",
    "    \n",
    "    def initSession(self):\n",
    "        assert self.optimizers_defined, \"Create optimizers before initializing the session.\"\n",
    "        with self.graph.as_default():\n",
    "            self.session = tf.Session()\n",
    "            self.session.run(tf.global_variables_initializer())\n",
    "            self.session.run(self.batch_assign_op)\n",
    "            \n",
    "    def getObjRegistrationError(self):\n",
    "        if self.obj_true is None:\n",
    "            return np.nan\n",
    "        recons_obj = self.session.run(self.tf_obj)\n",
    "        shift, err, phase = register_translation(recons_obj, self.obj_true, upsample_factor=10)\n",
    "        shift, err, phase = register_translation(recons_obj * np.exp(-1j * phase), self.obj_true, upsample_factor=10)\n",
    "        return err\n",
    "\n",
    "    def getProbeRegistrationError(self):\n",
    "        if (self.probe_true is None) or (not self.probe_recons):\n",
    "            return np.nan\n",
    "        recons_probe = self.session.run(self.tf_probe)\n",
    "        shift, err, phase = register_translation(recons_probe, self.probe_true, upsample_factor=10)\n",
    "        shift, err, phase = register_translation(recons_probe * np.exp(-1j * phase), self.probe_true, upsample_factor=10)\n",
    "        return err\n",
    "    \n",
    "    def run(self, \n",
    "            validation_frequency: int = 1,\n",
    "            improvement_threshold: float = 5e-4,\n",
    "            patience: int = 50,\n",
    "            patience_increase_factor: float = 1.5,\n",
    "            max_iters: int = 5000,\n",
    "            debug_output: bool = True,\n",
    "            debug_output_epoch_frequency: int = 10,\n",
    "            probe_fixed_epochs=0) -> None:\n",
    "        \n",
    "        print('epochs','training_loss','obj_err','probe_err','patience',\n",
    "              'validation_loss','validation_best_loss')\n",
    "        \n",
    "        epochs_this = 0\n",
    "        index = len(self.data)\n",
    "        for i in tqdm(range(max_iters)):\n",
    "            ix = index + i\n",
    "            \n",
    "            if self.probe_recons and epochs_this >= probe_fixed_epochs: \n",
    "                _ = self.session.run(self.probe_minimize_op)\n",
    "            \n",
    "            lossval, _ = self.session.run([self.training_loss, \n",
    "                                           self.obj_minimize_op])\n",
    "            _ = self.session.run(self.batch_assign_op)\n",
    "            self.data.loc[ix, 'loss'] = lossval\n",
    "            \n",
    "            if ix == 0:\n",
    "                self.data.loc[0, 'epoch'] = 0\n",
    "                continue\n",
    "            elif ix % (self.train_ndiffs // self.batch_size) != 0:\n",
    "                self.data.loc[ix, 'epoch'] = self.data['epoch'][ix-1]\n",
    "                continue\n",
    "            \n",
    "            self.data.loc[ix, 'epoch'] = self.data['epoch'][ix-1] + 1 \n",
    "            epochs_this += 1\n",
    "            \n",
    "            if epochs_this % validation_frequency != 0:\n",
    "                continue\n",
    "            validation_lossval = self.session.run(self.validation_loss)\n",
    "            self.data.loc[ix, 'validation_loss'] = validation_lossval\n",
    "            \n",
    "            obj_registration_error = self.getObjRegistrationError()\n",
    "            self.data.loc[ix, 'obj_error'] = obj_registration_error\n",
    "            \n",
    "            probe_registration_error = self.getProbeRegistrationError()\n",
    "            self.data.loc[ix, 'probe_error'] = probe_registration_error\n",
    "            \n",
    "            validation_best_loss = np.inf if ix == 0 else self.data['validation_loss'][:-1].min()\n",
    "            \n",
    "            if validation_lossval <= validation_best_loss:\n",
    "                if np.abs(validation_lossval - validation_best_loss) > validation_best_loss * improvement_threshold:\n",
    "                    patience = max(patience, epochs_this * patience_increase_factor)\n",
    "                \n",
    "            self.data.loc[ix, 'patience'] = patience\n",
    "                \n",
    "            if debug_output and epochs_this % debug_output_epoch_frequency == 0:\n",
    "                print(f'{epochs_this} '\n",
    "                       + f'{lossval:8.7g} '\n",
    "                       + f'{obj_registration_error:8.7g} '\n",
    "                       + f'{probe_registration_error:8.7g} '\n",
    "                       + f'{patience:8.7g} '\n",
    "                       + f'{validation_lossval:8.7g} '\n",
    "                       + f'{validation_best_loss:8.7g}')\n",
    "            \n",
    "            if epochs_this >= patience:\n",
    "                break\n",
    "                \n",
    "    \n",
    "    def genPlotsRecons(self):\n",
    "        \n",
    "        recons_obj = self.session.run(self.tf_obj)[npix:-npix, npix:-npix]\n",
    "        \n",
    "        plt.figure(figsize=[8,3])\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.pcolormesh(np.abs(recons_obj), cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.pcolormesh(np.angle(recons_obj), cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    def genPlotMetrics(self):\n",
    "        fig, axs = plt.subplots(1,3,figsize=[12,3])\n",
    "        axs[0].plot(np.log(self.data['loss'].dropna()))\n",
    "        axs[0].set_title('loss')\n",
    "        \n",
    "        axs[1].plot(self.data['obj_error'].dropna())\n",
    "        axs[1].set_title('obj_error')\n",
    "        \n",
    "        axs[2].plot(np.log(self.data['validation_loss'].dropna()))\n",
    "        axs[2].set_title('validation_loss')\n",
    "        plt.show()\n",
    "        \n",
    "    def getClipOp(self, max_abs: float=1.0) -> None:\n",
    "        \"\"\"Not used for now\"\"\"\n",
    "        with self.graph.as_default():\n",
    "            obj_reshaped = tf.reshape(self.tf_obj, [2, -1])\n",
    "            obj_clipped = tf.clip_by_norm(obj_reshaped, max_abs, axes=[0])\n",
    "            obj_clipped_reshaped = tf.reshape(obj_clipped, [-1])\n",
    "            clipped = tf.assign(self.tf_obj, obj_clipped_reshaped, name='clip_op')\n",
    "        return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tfNearFieldPtychoReconsFromSimulation(tfNearFieldPtychoRecons):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 simulation: NFPtychoSimulation,\n",
    "                 obj_guess: Optional[np.ndarray] = None,\n",
    "                 probe_guess: Optional[np.ndarray] = None,\n",
    "                 probe_recons: bool = False,\n",
    "                 batch_size: int = 0,\n",
    "                 n_validation_diffs: int = 0) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.simulation = simulation\n",
    "        self.probe_params = simulation.probe_params\n",
    "        self.obj_params = simulation.obj_params\n",
    "        self.det_params = simulation.det_params\n",
    "        \n",
    "        self.positions = simulation.positions\n",
    "        self.diffraction_mods = simulation.diffraction_mods\n",
    "        self.diffraction_mods_shifted = np.fft.fftshift(self.diffraction_mods, axes=(-1,-2))\n",
    "        self.prop_kernel = simulation.prop_kernel\n",
    "        \n",
    "        self.obj_true = simulation.obj_true\n",
    "        self.probe_true = simulation.probe_true\n",
    "        \n",
    "        self.probe_recons = probe_recons\n",
    "        if not probe_recons:\n",
    "            self.probe_guess = self.probe_true\n",
    "        \n",
    "        self.setObjProbeGuess(obj_guess, probe_guess)\n",
    "        \n",
    "        self.setTrainingAndValidation(n_validation_diffs, batch_size)\n",
    "        \n",
    "        # Tensorflow setup\n",
    "        self.createGraphAndVars()\n",
    "        self.initDataSet()\n",
    "        \n",
    "        self.optimizers_defined = False\n",
    "        \n",
    "        self.data = DataFrame(columns=['loss','epoch','obj_error','probe_error','validation_loss','patience'],\n",
    "                              dtype='float32')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
